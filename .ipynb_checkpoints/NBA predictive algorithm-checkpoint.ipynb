{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data product is meant as a beginner project and is largley taken from http://adventuresinmachinelearning.com/python-tensorflow-tutorial/\n",
    "\n",
    "\n",
    "For this predictive algorithm, we will use numpy and tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set our learning parameters - these can be changed to optimize our processing speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need placeholders for the trainng algorithm - the x placeholder is the input matrix while y is the output matrix that will determine which team will win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,312])\n",
    "y = tf.placeholder(tf.float32,shape=[None,1],name = \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will have 4 layers: the input layer, two hidden layers ,sizes 200 and 100 respectivley(will be changed later to see its effect on the prediction) and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting input to first layer\n",
    "W1 = tf.Variable(tf.random_normal([312, 200], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([200]), name='b1')\n",
    "\n",
    "# connecting first to second layer\n",
    "W2 = tf.Variable(tf.random_normal([200, 100], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([100]), name='b2')\n",
    "\n",
    "# connecting second to output layer\n",
    "W3 = tf.Variable(tf.random_normal([100, 1], stddev=0.03), name='W3')\n",
    "b3 = tf.Variable(tf.random_normal([1]), name='b3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these random weights, we can perform forward propagation to calculate each of the hidden layers and the final output layer. We use the relu activation function in calculating hidden layers. In the end we use the softmax function to get an prediction on the outcome of the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input to first layer\n",
    "hidden_one = tf.add(tf.matmul(x,W1),b1)\n",
    "hidden_one = tf.nn.relu(hidden_one)\n",
    "\n",
    "#first to second layer\n",
    "hidden_two = tf.add(tf.matmul(W1,W2),b2)\n",
    "hidden_two = tf.nn.relu(hidden_two)\n",
    "\n",
    "#output layer\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_two,W3),b3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our cost function uses the log(x) function, we need to ensure that the log(0) scenario does not happen. This will result in an NaN error. Clipping these values will negate these errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clipped = tf.clip_by_value(y_,1e-10,0.9999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the cost function and optimizer.\n",
    "\n",
    "Our cost function is the cross-entropy function \n",
    "    \\begin{align}\n",
    "    J = -\\frac{1}{m} \\sum_{i=1}^m \\sum_{j=1}^n y_j^{(i)}log(y_j\\_^{(i)}) + (1 – y_j^{(i)})log(1 – y_j\\_^{(i)})\n",
    "    \\end{align}\n",
    "    \n",
    "Where the ith variable is the predicted value of the current training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cost function\n",
    "cost_func = tf.reduce_mean(tf.reduce_sum(y*tf.log(y_clipped) + (1-y) * tf.log(1-y_clipped),axis=1))\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning).minimize(cost_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an accuracy testing operation. We can test how well our algorithm is performing by comparing the predicted result with the correct result in our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get our training set and labels from their respective folders. They are stored in .csv files and we can convert them into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = np.genfromtxt(\"DataSets/trainingSet - Copy.csv\",delimiter=',', dtype=\"float32\")\n",
    "labels = np.genfromtxt(\"Labels/trainingSet - Copy.csv\",delimiter=',', dtype=\"float32\")\n",
    "\n",
    "labels = np.reshape(labels,(len(labels),1))\n",
    "\n",
    "test_x = np.genfromtxt(\"DataSets/testingSet - Copy.csv\", delimiter=',', dtype = \"float32\")\n",
    "test_y = np.genfromtxt(\"Labels/testingSet - Copy.csv\",delimiter=',',dtype = \"float32\")\n",
    "\n",
    "test_y = np.reshape(test_y,(len(test_y),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the labels set from a np array with one column to an array to two columns. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = np.empty((0,2))\n",
    "for i in range(0,len(one_labels)):\n",
    "    if(one_labels[i] == 1):\n",
    "        labels = np.vstack((labels,(1,0)))\n",
    "    else:\n",
    "        labels = np.vstack((labels,(0,1)))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run our session, training in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-10-0bc7dda8f9ec>\u001b[0m(17)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     16 \u001b[1;33m            \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 17 \u001b[1;33m            _, c = sess.run([optimizer, cost_func], feed_dict={x: batch_x,\n",
      "\u001b[0m\u001b[1;32m     18 \u001b[1;33m                                                          y: batch_y})\n",
      "\u001b[0m\u001b[1;32m     19 \u001b[1;33m            \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> pp x\n",
      "<tf.Tensor 'Placeholder:0' shape=(?, 312) dtype=float32>\n",
      "ipdb> px\n",
      "*** NameError: name 'px' is not defined\n",
      "ipdb> p x\n",
      "<tf.Tensor 'Placeholder:0' shape=(?, 312) dtype=float32>\n",
      "ipdb> pp y\n",
      "<tf.Tensor 'labels:0' shape=(?, 1) dtype=float32>\n",
      "ipdb> pp batch_y\n",
      "array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.]], dtype=float32)\n",
      "ipdb> a\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "prediction = y_\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        i=0\n",
    "        while i < len(trainingSet):\n",
    "            start = i\n",
    "            end = i+batch_size\n",
    "            batch_x = np.array(trainingSet[start:end])\n",
    "            batch_y = np.array(labels[start:end])\n",
    "            \n",
    "            set_trace()\n",
    "            _, c = sess.run([optimizer, cost_func], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            epoch_loss += c\n",
    "            i+=batch_size\n",
    "\n",
    "        print('Epoch', epoch+1, 'completed out of',epochs,'loss:',epoch_loss)\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "    print('Accuracy:',accuracy.eval({x:test_x, y:test_y}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
